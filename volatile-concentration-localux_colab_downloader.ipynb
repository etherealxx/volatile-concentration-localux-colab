{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/etherealxx/volatile-concentration-localux-colab/blob/main/volatile-concentration-localux_colab_downloader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model Downloader (try this one)\n",
        "%cd /content\n",
        "!git clone https://github.com/etherealxx/volatile-concentration-localux-colab /content/colabtools\n",
        "!pip install -q gradio\n",
        "!apt -y install -qq aria2\n",
        "\n",
        "import os, pickle\n",
        "import gradio as gr\n",
        "from IPython.display import clear_output\n",
        "\n",
        "!python /content/colabtools/cloneall2.py\n",
        "!python /content/colabtools/choosemodel2.py\n",
        "\n",
        "if os.path.exists('/content/sortedcolabname.pkl'):\n",
        "  with open('/content/sortedcolabname.pkl', 'rb') as f:\n",
        "      sortedcolabname = pickle.load(f)\n",
        "\n",
        "everycolab = '/content/camendurus/lite'\n",
        "modelischosen = False\n",
        "modelchosenmessage = ''\n",
        "chosencolabname = ''\n",
        "\n",
        "def modelchosen(chosenmodel):\n",
        "  global modelischosen\n",
        "  global modelchosenmessage\n",
        "  global chosencolabname\n",
        "  modelchosenmessage = \"\u001b[1;32mModel \" + chosenmodel + \" was chosen. It'll be downloaded soon. Continue scroll down and wait for the webui to be loaded.\"\n",
        "  textbox_text = f\"Model '{chosenmodel} was chosen. It'll be downloaded soon. Continue scroll down and wait for the webui to be loaded.\"\n",
        "  chosencolabname = chosenmodel\n",
        "  modelischosen = True\n",
        "  return [gr.Button.update(visible=False), gr.Textbox.update(value=textbox_text, visible=True)]\n",
        "\n",
        "with gr.Blocks() as vclcolab:\n",
        "    with gr.Column():\n",
        "      choose = gr.Dropdown(sortedcolabname, label=\"Choose Your Model\")\n",
        "      confirm = gr.Button(\"Use This Model\", variant=\"primary\", visible=True)\n",
        "      donetext = gr.Textbox(\"\", label=\"\", visible=False)\n",
        "      confirm.click(modelchosen, inputs=[choose], outputs=[confirm, donetext])\n",
        "vclcolab.launch()\n",
        "\n",
        "while True:\n",
        "  if modelischosen:\n",
        "    clear_output(wait=True)\n",
        "    print(modelchosenmessage)\n",
        "    print('\u001b[0m')\n",
        "    break\n",
        "\n",
        "aria2c_lines = []\n",
        "\n",
        "if chosencolabname:\n",
        "   colabfilename = chosencolabname + '_webui_colab.ipynb'\n",
        "   if os.path.exists(os.path.join(everycolab, colabfilename)):\n",
        "      with open(os.path.join(everycolab, colabfilename), 'r', encoding='utf-8') as f:\n",
        "          for line in f:\n",
        "              stripped_line = line.strip()\n",
        "              if stripped_line.startswith('\"!aria2c'):\n",
        "                  aria2c_lines.append(stripped_line)\n",
        "\n",
        "if aria2c_lines:\n",
        "  with open('/content/arialist.pkl', 'wb') as f:\n",
        "      pickle.dump(aria2c_lines, f)\n",
        "\n",
        "!python /content/colabtools/runaria2.py"
      ],
      "metadata": {
        "cellView": "form",
        "id": "HRLSD-HXLRNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaAJk33ppFw1",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title (original colab code)\n",
        "from IPython.display import clear_output\n",
        "%cd /content\n",
        "!git clone https://github.com/etherealxx/volatile-concentration-localux-colab /content/colabtools\n",
        "!python /content/colabtools/cloneall.py\n",
        "!pip install -q gradio \n",
        "clear_output(wait=True)\n",
        "!python /content/colabtools/choosemodel.py\n",
        "\n",
        "%env TF_CPP_MIN_LOG_LEVEL=1\n",
        "\n",
        "!apt -y update -qq\n",
        "!wget http://launchpadlibrarian.net/367274644/libgoogle-perftools-dev_2.5-2.2ubuntu3_amd64.deb\n",
        "!wget https://launchpad.net/ubuntu/+source/google-perftools/2.5-2.2ubuntu3/+build/14795286/+files/google-perftools_2.5-2.2ubuntu3_all.deb\n",
        "!wget https://launchpad.net/ubuntu/+source/google-perftools/2.5-2.2ubuntu3/+build/14795286/+files/libtcmalloc-minimal4_2.5-2.2ubuntu3_amd64.deb\n",
        "!wget https://launchpad.net/ubuntu/+source/google-perftools/2.5-2.2ubuntu3/+build/14795286/+files/libgoogle-perftools4_2.5-2.2ubuntu3_amd64.deb\n",
        "!apt install -qq libunwind8-dev\n",
        "!dpkg -i *.deb\n",
        "%env LD_PRELOAD=libtcmalloc.so\n",
        "!rm *.deb\n",
        "\n",
        "!apt -y install -qq aria2\n",
        "!pip install -q torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 torchtext==0.14.1 torchdata==0.5.1 --extra-index-url https://download.pytorch.org/whl/cu116 -U\n",
        "!pip install -q xformers==0.0.16 triton==2.0.0 -U\n",
        "!apt -y install -qq aria2\n",
        "\n",
        "!git clone https://github.com/etherealxx/volatile-concentration-localux /content/breaktherules\n",
        "!python /content/breaktherules/breaktherules.py\n",
        "\n",
        "%cd /content/volatile-concentration-localux\n",
        "!python /content/colabtools/runaria.py\n",
        "!sed -i -e '''/    prepare_environment()/a\\    os.system\\(f\\\"\"\"sed -i -e ''\\\"s/dict()))/dict())).cuda()/g\\\"'' /content/volatile-concentration-localux/repositories/stable-diffusion-stability-ai/ldm/util.py\"\"\")''' /content/volatile-concentration-localux/launch.py\n",
        "!sed -i -e 's/\\\"sd_model_checkpoint\\\"\\,/\\\"sd_model_checkpoint\\,sd_vae\\,CLIP_stop_at_last_layers\\\"\\,/g' /content/volatile-concentration-localux/modules/shared.py\n",
        "\n",
        "!python launch.py --listen --xformers --enable-insecure-extension-access --theme dark --gradio-queue --multiple"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (debug)\n",
        "import os, math, subprocess, pickle\n",
        "from IPython.display import clear_output\n",
        "\n",
        "!apt -y install -qq aria2\n",
        "clear_output(wait=True)\n",
        "\n",
        "everycolab = '/content/camendurus/lite'\n",
        "everycolabname = []\n",
        "colabnamepair = []\n",
        "for colabname in os.listdir(everycolab):\n",
        "  colabnamepruned = colabname.partition('_webui_colab.ipynb')[0]\n",
        "  everycolabname.append(colabnamepruned)\n",
        "\n",
        "sortedcolabname = sorted(everycolabname)\n",
        "totalcolabcount = len(everycolabname)\n",
        "for i, colabname in enumerate(sortedcolabname):\n",
        "  halfall = math.ceil(totalcolabcount / 2)\n",
        "  numberedname = \"{} | {}\".format(i, colabname.ljust(30))\n",
        "  if i <= halfall:\n",
        "    colabnamepair.append(numberedname)\n",
        "  else:\n",
        "    rev_index = (i - halfall) - 1\n",
        "    colabnamepair[rev_index] += \"\\t\" + numberedname\n",
        "\n",
        "for colabpair in colabnamepair:\n",
        "  print(colabpair)\n",
        "\n",
        "choosenumber = input('Choose the number of the model you want: ')\n",
        "if choosenumber.isdigit() and int(choosenumber) < totalcolabcount:\n",
        "  chosencolabname = sortedcolabname[int(choosenumber)] + '_webui_colab.ipynb'\n",
        "  print(\"Preparing to download model from \" + chosencolabname)\n",
        "\n",
        "aria2c_lines = []\n",
        "with open(os.path.join(everycolab, chosencolabname), 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        stripped_line = line.strip()\n",
        "        if stripped_line.startswith('\"!aria2c'):\n",
        "            aria2c_lines.append(stripped_line)\n",
        "\n",
        "# print(aria2c_lines)\n",
        "with open('/content/arialist.pkl', 'wb') as f:\n",
        "    pickle.dump(aria2c_lines, f)\n",
        "\n",
        "!python /content/runaria.py"
      ],
      "metadata": {
        "cellView": "form",
        "id": "K3uKK-_4ldJB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}